# Kritik Maliyet SorunlarÄ± Raporu

**Tarih**: 2025-10-24  
**Proje**: Bilgee (TaktikAI)  
**Durum**: ğŸ”´ Kritik - Acil MÃ¼dahale Gerekli

## Ã–zet

Bu rapor, TaktikAI uygulamasÄ±nda tespit edilen tÃ¼m kritik maliyet sorunlarÄ±nÄ± detaylÄ±ca incelemektedir. Sistemde AI API kullanÄ±mÄ±, token limitleri ve kaynak yÃ¶netimi ile ilgili Ã¶nemli optimizasyon fÄ±rsatlarÄ± bulunmaktadÄ±r.

---

## ğŸ”´ Kritik Sorun #1: PahalÄ± AI Modeli KullanÄ±mÄ±

**Dosya**: `lib/data/repositories/ai_service.dart:626`

**Sorun**: 
Chat Ã¶zellikleri iÃ§in `gemini-1.5-pro-latest` modeli kullanÄ±lÄ±yor. Pro model, Flash modellerine gÃ¶re **~15-20 kat daha pahalÄ±dÄ±r**.

```dart
model: 'gemini-1.5-pro-latest',  // âŒ Ã‡ok pahalÄ±!
```

**Maliyet Etkisi**: 
- Pro model: ~$0.00125 per 1K input tokens
- Flash model: ~$0.000075 per 1K input tokens
- **Potansiyel tasarruf**: %93+ maliyet dÃ¼ÅŸÃ¼ÅŸÃ¼

**Ã–nerilen Ã‡Ã¶zÃ¼m**:
- TÃ¼m chat fonksiyonlarÄ± iÃ§in `gemini-2.0-flash-lite-001` kullanÄ±lmalÄ±
- Sadece kritik analitik gÃ¶revler iÃ§in Pro model ayrÄ±lmalÄ±
- Model seÃ§imi kullanÄ±cÄ± tarafÄ±na deÄŸil, backend tarafÄ±nda kontrol edilmeli

**Ã–ncelik**: ğŸ”´ ACÄ°L - YÃ¼ksek hacimli kullanÄ±mda gÃ¼nlÃ¼k yÃ¼zlerce dolar fark yaratÄ±r

---

## ğŸ”´ Kritik Sorun #2: AÅŸÄ±rÄ± YÃ¼ksek Token Limitleri

**Dosya**: `functions/src/ai.js:10`

**Sorun**:
Maximum output token limiti 50,000 olarak ayarlanmÄ±ÅŸ. Bu aÅŸÄ±rÄ± yÃ¼ksek bir deÄŸerdir.

```javascript
const GEMINI_MAX_OUTPUT_TOKENS = parseInt(process.env.GEMINI_MAX_OUTPUT_TOKENS || "50000", 10);
```

**Maliyet Etkisi**:
- Gereksiz yere uzun yanÄ±tlar Ã¼retme riski
- Her istek iÃ§in yÃ¼ksek output token maliyeti
- Ortalama kullanÄ±mÄ±n Ã§ok Ã¼stÃ¼nde limit

**Ã–nerilen Ã‡Ã¶zÃ¼m**:
- Genel kullanÄ±m iÃ§in: 4,000 - 8,000 tokens
- Chat iÃ§in: 2,000 - 3,000 tokens
- Strateji oluÅŸturma iÃ§in: 8,000 - 12,000 tokens
- AtÃ¶lye iÃ§eriÄŸi iÃ§in: 6,000 - 10,000 tokens

**Ã–ncelik**: ğŸŸ¡ YÃœKSEK - Kademeli azaltma ile uygulanabilir

---

## ğŸ”´ Kritik Sorun #3: Uzun Prompt ÅablonlarÄ±

**Dosya**: `lib/core/prompts/workshop_prompts.dart:47-48`

**Sorun**:
Kod iÃ§inde aÃ§Ä±kÃ§a belirtilmiÅŸ: "Ä°Ã§erik uzunluÄŸu kÄ±sÄ±tlarÄ± (maliyet ve Firestore limitlerini korumak iÃ§in)"

Ancak prompt ÅŸablonlarÄ± hala Ã§ok uzun:
- `workshop_prompts.dart`: 90 satÄ±r
- `strategy_prompts.dart`: 208 satÄ±r
- Asset prompts: 5.4KB (yks_prompt.md)

**Maliyet Etkisi**:
- Her istek iÃ§in 3,000-5,000+ token input
- Gereksiz context ve aÃ§Ä±klama metni
- Her Ã§aÄŸrÄ±da tekrarlanan statik iÃ§erik

**Ã–nerilen Ã‡Ã¶zÃ¼m**:
1. Prompt ÅŸablonlarÄ±nÄ± %30-40 kÄ±saltÄ±n
2. Ortak instruction'larÄ± sistem mesajÄ±na taÅŸÄ±yÄ±n
3. Ã–rnekleri daha kÄ±sa tutun
4. Gereksiz formatlamayÄ± kaldÄ±rÄ±n

**Ã–ncelik**: ğŸŸ¡ YÃœKSEK - Kalite kaybÄ± olmadan optimize edilebilir

---

## ğŸŸ  Kritik Sorun #4: Chat HafÄ±za YÃ¶netimi VerimsizliÄŸi

**Dosya**: `lib/data/repositories/ai_service.dart:54-86`

**Sorun**:
Chat hafÄ±zasÄ± ancak 1200 karakteri geÃ§ince sÄ±kÄ±ÅŸtÄ±rÄ±lÄ±yor. Bu sÄ±nÄ±ra ulaÅŸana kadar tÃ¼m conversation history her istekte gÃ¶nderiliyor.

```dart
const int maxChars = 1200;  // Ã‡ok yÃ¼ksek
if (updatedHistory.length > maxChars) {
  // SÄ±kÄ±ÅŸtÄ±rma yapÄ±lÄ±yor
}
```

**Maliyet Etkisi**:
- Uzun conversation'larda exponential token artÄ±ÅŸÄ±
- Ä°lk 5-10 mesajda sÄ±nÄ±ra ulaÅŸmÄ±yor, maliyet birikimi
- Her yeni mesajda Ã¶nceki tÃ¼m context tekrar iÅŸleniyor

**Ã–nerilen Ã‡Ã¶zÃ¼m**:
1. maxChars deÄŸerini 600-800'e dÃ¼ÅŸÃ¼rÃ¼n
2. Son 3-5 mesaj yerine sliding window kullanÄ±n
3. Semantic compression uygulayÄ±n (Ã¶nemli bilgileri Ã¶zetleyin)
4. Timestamp bazlÄ± expiration ekleyin

**Ã–ncelik**: ğŸŸ¡ ORTA - SÄ±k chat kullanan kullanÄ±cÄ±larda etkili

---

## ğŸŸ  Kritik Sorun #5: GÃ¼nlÃ¼k Quota Tracking EksikliÄŸi

**Dosya**: KullanÄ±cÄ± arayÃ¼zÃ¼nde yok, sadece backend'de mevcut

**Sorun**:
KullanÄ±cÄ±lar gÃ¼nlÃ¼k AI kullanÄ±m kotalarÄ±nÄ± (100 "yÄ±ldÄ±z") gÃ¶remiyorlar. Backend'de kontrol var (`functions/src/ai.js:69-85`) ama kullanÄ±cÄ± bilgilendirilmiyor.

```javascript
// Backend'de kota var ama UI'da gÃ¶sterilmiyor
const starRef = db.collection("users").doc(request.auth.uid).collection("stars").doc(today);
if (currentBalance <= 0) {
  throw new HttpsError("resource-exhausted", "GÃ¼nlÃ¼k AI kullanÄ±m limitine ulaÅŸtÄ±nÄ±z.");
}
```

**Maliyet Etkisi**:
- KullanÄ±cÄ±lar bilinÃ§sizce kota tÃ¼ketir
- Kota bitince sÃ¼rpriz hata alÄ±r
- KullanÄ±m davranÄ±ÅŸÄ± optimize edilemez
- Premium upgrade motivasyonu dÃ¼ÅŸÃ¼k

**Ã–nerilen Ã‡Ã¶zÃ¼m**:
1. Ana ekranda kota gÃ¶stergesi ekleyin (Ã¶rn: "â­ 73/100")
2. %80-90'a yaklaÅŸÄ±nca uyarÄ± gÃ¶sterin
3. Kota bitince gÃ¼zel bir yÃ¼kseltme ekranÄ± gÃ¶sterin
4. HaftalÄ±k kullanÄ±m trendini gÃ¶sterin

**Ã–ncelik**: ğŸŸ¢ ORTA - KullanÄ±cÄ± deneyimi ve bilinÃ§lendirme iÃ§in Ã¶nemli

---

## ğŸŸ  Kritik Sorun #6: Rate Limiting Parametreleri

**Dosya**: `functions/src/ai.js:11-13`

**Sorun**:
Rate limit deÄŸerleri test/geliÅŸtirme iÃ§in ayarlanmÄ±ÅŸ gibi gÃ¶rÃ¼nÃ¼yor:
- 60 saniyede 5 istek (user bazlÄ±)
- 60 saniyede 20 istek (IP bazlÄ±)

Bu deÄŸerler production iÃ§in Ã§ok gevÅŸek:

```javascript
const GEMINI_RATE_LIMIT_MAX = parseInt(process.env.GEMINI_RATE_LIMIT_MAX || "5", 10);
const GEMINI_RATE_LIMIT_IP_MAX = parseInt(process.env.GEMINI_RATE_LIMIT_IP_MAX || "20", 10);
```

**Maliyet Etkisi**:
- Botlar veya script'ler sistemi exploit edebilir
- Dakikada 5 istek = saatte 300 istek = gÃ¼nde 7,200 istek (tek user!)
- IP bazlÄ± limit tek device'da shared IP durumlarÄ±nda sorun yaratabilir

**Ã–nerilen Ã‡Ã¶zÃ¼m**:
1. User limiti: 3-4 istek/dakika
2. Burst allowance ekleyin (ilk 10 istek serbest, sonra throttle)
3. Premium kullanÄ±cÄ±lar iÃ§in farklÄ± tier
4. Suspicious pattern detection ekleyin

**Ã–ncelik**: ğŸŸ¢ ORTA - Abuse prevention iÃ§in Ã¶nemli

---

## ğŸŸ¢ Kritik Sorun #7: Model SeÃ§im MantÄ±ÄŸÄ±

**Dosya**: `functions/src/ai.js:38-48`

**Sorun**:
Model seÃ§imi request'ten geliyor ve string match ile yapÄ±lÄ±yor. Client-side'da yanlÄ±ÅŸ model seÃ§ilmesi riski var.

```javascript
let modelId = "gemini-2.0-flash-lite-001";  // Default
const reqModel = typeof request.data?.model === "string" ? String(request.data.model).toLowerCase().trim() : "";
if (reqModel) {
  if (reqModel.includes("pro")) {
    modelId = "gemini-2.0-flash-001";  // PahalÄ± modele geÃ§iÅŸ!
  }
}
```

**Maliyet Etkisi**:
- Client bug'Ä± veya hacker "pro" iÃ§eren string gÃ¶nderebilir
- Model maliyeti kontrolÃ¼ backend'de deÄŸil client'da
- A/B testing veya dynamic optimization zorlaÅŸÄ±r

**Ã–nerilen Ã‡Ã¶zÃ¼m**:
1. Model seÃ§imini backend'de task type'a gÃ¶re yapÄ±n
2. Client'dan model seÃ§imine izin vermeyin
3. Task type'larÄ± tanÄ±mlayÄ±n: "chat", "strategy", "workshop", "quiz"
4. Her task type iÃ§in optimal model backend'de belirlensin

**Ã–ncelik**: ğŸŸ¢ DÃœÅÃœK - Security ve cost control iÃ§in best practice

---

## ğŸ“Š Tahmini Maliyet Tasarruf Potansiyeli

YukarÄ±daki sorunlarÄ±n Ã§Ã¶zÃ¼lmesi durumunda:

| Sorun | Mevcut Durum | Optimize SonrasÄ± | Tasarruf |
|-------|--------------|------------------|----------|
| Pro Model KullanÄ±mÄ± | ~$15/1M tokens | ~$1/1M tokens | %93 |
| Token Limitleri | 50K max | 8K ortalama | %60-80 |
| Prompt UzunluÄŸu | 5K tokens avg | 3K tokens avg | %40 |
| Chat HafÄ±zasÄ± | Unlimited growth | 800 char limit | %30-50 |
| **TOPLAM TAHMÄ°NÄ°** | **$100/gÃ¼n** | **$15-25/gÃ¼n** | **%75-85** |

*Not: YukarÄ±daki rakamlar 1,000 premium kullanÄ±cÄ± ve gÃ¼nde ortalama 5 AI isteÄŸi varsayÄ±mÄ±na dayalÄ±dÄ±r.*

---

## ğŸ”§ Acil Aksiyon PlanÄ±

### Hemen YapÄ±lacaklar (24 saat iÃ§inde):
1. âœ… Bu raporu oluÅŸtur ve paylaÅŸ
2. ğŸ”´ Pro model kullanÄ±mÄ±nÄ± Flash'a Ã§evir (ai_service.dart:626)
3. ğŸ”´ Token limitlerini dÃ¼ÅŸÃ¼r (baÅŸlangÄ±Ã§: 20K, hedef: 8K)

### Bu Hafta (7 gÃ¼n iÃ§inde):
4. ğŸŸ¡ Chat hafÄ±za limitini 600-800'e dÃ¼ÅŸÃ¼r
5. ğŸŸ¡ Prompt ÅŸablonlarÄ±nÄ± optimize et (%30 kÄ±saltma)
6. ğŸŸ¡ Kota gÃ¶stergesini UI'a ekle

### Bu Ay (30 gÃ¼n iÃ§inde):
7. ğŸŸ¢ Rate limiting'i sÄ±kÄ±laÅŸtÄ±r
8. ğŸŸ¢ Model seÃ§imini backend'e taÅŸÄ±
9. ğŸŸ¢ Usage analytics dashboard oluÅŸtur
10. ğŸŸ¢ Maliyet izleme ve alerting sistemi kur

---

## ğŸ“ˆ Ä°zleme Metrikleri

Optimizasyon sonrasÄ± izlenecek metrikler:

1. **GÃ¼nlÃ¼k AI Maliyeti**: Firebase Cloud Functions logs
2. **Ortalama Token KullanÄ±mÄ±**: Input + Output tokens per request
3. **KullanÄ±cÄ± BaÅŸÄ±na Maliyet**: Cost / Active Premium Users
4. **Model DaÄŸÄ±lÄ±mÄ±**: Flash vs Pro usage ratio
5. **Kota Doluluk OranÄ±**: Users hitting daily limit
6. **Request BaÅŸarÄ± OranÄ±**: Errors due to limits

---

## ğŸ“ Notlar ve VarsayÄ±mlar

1. Maliyet hesaplamalarÄ± Google Cloud Gemini API fiyatlandÄ±rmasÄ±na dayalÄ±dÄ±r (Ekim 2024)
2. Premium kullanÄ±cÄ± sayÄ±sÄ± ve kullanÄ±m sÄ±klÄ±ÄŸÄ± tahmindir
3. Prompt optimization'da kalite kaybÄ± olmayacaÄŸÄ± varsayÄ±lmÄ±ÅŸtÄ±r
4. Rate limiting deÄŸiÅŸiklikleri mevcut kullanÄ±cÄ± deneyimini etkileyebilir

---

## âœ… SonuÃ§ ve Ã–neriler

TaktikAI uygulamasÄ±nda **kritik seviyede maliyet optimizasyonu fÄ±rsatlarÄ±** tespit edilmiÅŸtir. 

**En acil sorun**: Gemini 1.5 Pro modelinin chat iÃ§in kullanÄ±lmasÄ±. Bu tek baÅŸÄ±na maliyetlerin %90+ oranÄ±nda artmasÄ±na neden olmaktadÄ±r.

**Ã–nerilen yaklaÅŸÄ±m**:
1. Ã–nce "dÃ¼ÅŸÃ¼k risk, yÃ¼ksek etki" deÄŸiÅŸiklikleri yapÄ±n (model deÄŸiÅŸimi, token limitleri)
2. Sonra "orta risk, orta etki" optimizasyonlarÄ± uygulayÄ±n (prompt kÄ±saltma, hafÄ±za yÃ¶netimi)
3. Son olarak "yapÄ±sal deÄŸiÅŸiklikler" yapÄ±n (backend refactoring, monitoring sistemi)

**Tahmini ROI**: 
- Ä°lk hafta: %60-70 maliyet azalmasÄ±
- Ä°lk ay: %75-85 maliyet azalmasÄ±
- Kalite kaybÄ±: Minimal (iyi test ile neredeyse sÄ±fÄ±r)

Bu optimizasyonlar aylÄ±k AI maliyetlerini **$3,000'den $500-750'ye dÃ¼ÅŸÃ¼rebilir** (1,000 aktif premium kullanÄ±cÄ± varsayÄ±mÄ± ile).

---

**Rapor HazÄ±rlayan**: GitHub Copilot - AI Code Analysis  
**Rapor Tarihi**: 24 Ekim 2025  
**Versiyon**: 1.0
